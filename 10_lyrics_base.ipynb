{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_lyrics_base.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBsJsHAcDzxs"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUlT9WyOD1gl"
      },
      "source": [
        "from fastbook import *\n",
        "from fastai.text.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGrbEYvvD7Kt"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yP5gfuRE5hx"
      },
      "source": [
        "## Practice Creating the Language Model DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSg3KRV4EVj2"
      },
      "source": [
        "# read and combine the data\n",
        "lyrics_data = pd.read_csv('sample_data/lyrics-data.csv')\n",
        "lyrics_data.rename(columns={\"ALink\": \"Link\"}, inplace=True)\n",
        "artist_data = pd.read_csv('sample_data/artists-data.csv')\n",
        "print(artist_data.columns, lyrics_data.columns)\n",
        "merged_dfs = lyrics_data.merge(artist_data, how='inner', on='Link')\n",
        "eng_artists = merged_dfs.loc[merged_dfs['Idiom'] == 'ENGLISH', ['Artist', 'SName', 'Lyric', 'Genre']].drop_duplicates(subset=['SName'])\n",
        "eng_artists.reset_index(inplace=True, drop=True)\n",
        "\n",
        "eng_artists.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owG1bzLfEX7m"
      },
      "source": [
        "artist_name = \"\"\n",
        "\n",
        "artist_df = eng_artists.loc[eng_artists['Artist'] == artist_name].reset_index(drop=True)\n",
        "artist_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF3rfL9ILLOA"
      },
      "source": [
        "## Create dataloader using fastai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cILz9WCzK27K"
      },
      "source": [
        "lang_model_block = DataBlock(\n",
        "    blocks=TextBlock.from_df('artist_df', seq_len=72, is_lm=True),\n",
        "    get_items=ColReader('Lyric')\n",
        ")\n",
        "lang_model_block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCIO_OFzL4B7"
      },
      "source": [
        "dls_lm = lang_model_block.dataloaders(artist_df, bs=128, seq_len=80)\n",
        "dls_lm.show_batch(max_n=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB0qZ-OfO-RH"
      },
      "source": [
        "# Train a model using transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVdFZNAuPCB6"
      },
      "source": [
        "learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, metrics=accuracy)\n",
        "learn.fit_one_cycle(5, 0.004)\n",
        "learn.unfreeze()\n",
        "# train for 20 more epochs on the new lr\n",
        "learn.fit_one_cycle(20, lr_max=slice(3e-6, 3e-4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v8sTDVXVlOU"
      },
      "source": [
        "# Predictions with Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrvVHSD1V_-V"
      },
      "source": [
        "def get_most_complex(start_text, preds):\n",
        "  max_len = 0\n",
        "  max_i = -1\n",
        "  for i, pred in enumerate(preds):\n",
        "    pred_cardinality = len(set(pred.split()))\n",
        "    if pred_cardinality > max_len:\n",
        "      max_len = pred_cardinality\n",
        "      max_i = i\n",
        "  \n",
        "  return_str = preds[max_i]\n",
        "\n",
        "  val = -1\n",
        "  occurrence = len(start_text.split())\n",
        "  for i in range(0, occurrence):\n",
        "    val = return_str.find(' ', val + 1)\n",
        "\n",
        "  return start_text + return_str[val:return_str.rfind('.')+1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0AIPXebX9QO"
      },
      "source": [
        "start_text = \"\"\n",
        "words = 60\n",
        "sentences = 5\n",
        "preds = [learn.predict(start_text, words, temperature=0.75)\n",
        "         for sentence in range(sentences)]\n",
        "\n",
        "get_most_complex(start_text, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrcLBrAHbp_c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}