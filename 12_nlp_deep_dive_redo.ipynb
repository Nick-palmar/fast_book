{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_nlp_deep_dive_redo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8JMhhooxh60",
        "outputId": "2c5d18fd-d860-43e0-f478-1896f408bcb3"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 186 kB 40.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 26.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 203 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Raz-vxl2y6mK",
        "outputId": "31a6fd70-ec0c-4891-e99c-a9e43b958896"
      },
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyOYCQmNzK7X"
      },
      "source": [
        "Path.BASE_PATH = path"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XelDpuxCzNeZ",
        "outputId": "35a36ade-316a-4a7b-b940-82ad22edb664"
      },
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "lines"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnksChHlz5OB"
      },
      "source": [
        "### Data Preprocessing\n",
        "- Preprocess the dataset for the language model\n",
        "- Manually tokenize and numericalize the data\n",
        "- Create batches for the model to read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "n_SJZ1P2zQYL",
        "outputId": "a40fc651-8499-4c13-fe3b-93965da16214"
      },
      "source": [
        "text = \" . \".join(line.strip() for line in lines)\n",
        "text[:50]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'one . two . three . four . five . six . seven . ei'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq_fEat_07gj",
        "outputId": "d532cd20-0965-4c4e-bac3-5bac40eef486"
      },
      "source": [
        "# get the tokens by splitting on spaces\n",
        "tokens = text.split()\n",
        "tokens[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_J9UXVd1FPy",
        "outputId": "05ed6297-c52d-4033-cf10-0c9ff41dec42"
      },
      "source": [
        "vocab = list(set(tokens))\n",
        "vocab[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one',\n",
              " 'hundred',\n",
              " 'twenty',\n",
              " 'eleven',\n",
              " 'fifty',\n",
              " 'six',\n",
              " 'forty',\n",
              " 'five',\n",
              " 'eighty',\n",
              " 'seventy']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NlHi48J1QfZ",
        "outputId": "c4816405-a84d-496b-fa94-0778fb8780c1"
      },
      "source": [
        "word2index = {word: i for i, word in enumerate(vocab)}\n",
        "word2index['two']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_U2eQPm1nGo",
        "outputId": "8ce865ac-256c-4f15-d357-28f01cbed324"
      },
      "source": [
        "num_tokens = [word2index[word] for word in tokens]\n",
        "num_tokens[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 22, 24, 22, 25, 22, 18, 22, 7, 22]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-8zFVpc1tkz",
        "outputId": "f79c76e8-fad7-4a23-aa41-329c41d65ad4"
      },
      "source": [
        "len_tks = 6\n",
        "\n",
        "for i in range(0,len_tks-4,3):\n",
        "  print(i)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FobGrNvb2kHU",
        "outputId": "5db3b2f1-5935-4537-9c71-78cf7e7a9adc"
      },
      "source": [
        "print(len(tokens))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1hM-xlw5OA2",
        "outputId": "bc3da8a3-d08f-4411-ef7e-7437b5043525"
      },
      "source": [
        "# want sequences of consecutive characters\n",
        "seq_len = 16\n",
        "seqs = [(torch.Tensor(num_tokens[i: i+seq_len]).long(), torch.Tensor(num_tokens[i+1:i+seq_len+1]).long()) for i in range(0,len(num_tokens)-seq_len-1, seq_len)]\n",
        "seqs[:2]                                                                                         "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 0, 22, 24, 22, 25, 22, 18, 22,  7, 22,  5, 22, 23, 22, 13, 22]),\n",
              "  tensor([22, 24, 22, 25, 22, 18, 22,  7, 22,  5, 22, 23, 22, 13, 22, 21])),\n",
              " (tensor([21, 22, 17, 22,  3, 22, 12, 22, 28, 22, 16, 22, 14, 22, 20, 22]),\n",
              "  tensor([22, 17, 22,  3, 22, 12, 22, 28, 22, 16, 22, 14, 22, 20, 22, 15]))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svHE4W8p2ox0"
      },
      "source": [
        "# want data in order\n",
        "# (0, m, 2m, ..., )\n",
        "\n",
        "def group_chunks(dset, bs):\n",
        "  m = len(dset) // bs\n",
        "  new_dset = []\n",
        "\n",
        "  for i in range(m):\n",
        "    new_dset += [dset[i + m*j] for j in range(bs)]\n",
        "  return new_dset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFxhtjY45DhL"
      },
      "source": [
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs), \n",
        "    group_chunks(seqs[cut:], bs), \n",
        "    bs=bs, drop_last=True, shuffle=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igAdPdXT17FV",
        "outputId": "4d8cb887-3470-4c49-f1b6-2e5d8ee6bc05"
      },
      "source": [
        "x, y = dls.one_batch()\n",
        "x.shape, y.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 16]), torch.Size([64, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnAg_mkB7ba7"
      },
      "source": [
        "### Experiment with RNNs\n",
        "- Write RNNs from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv3xunCD5NQo"
      },
      "source": [
        "class LMModel1(Module):\n",
        "  def __init__(self, vocab_sz, n_hidden):\n",
        "    self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "    self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "    self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "    self.h = 0\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # print(x.shape)\n",
        "    outs = []\n",
        "    for i in range(x.shape[1]):\n",
        "      # add the hidden state to the input to hidden state\n",
        "      self.h = self.h + self.i_h(x[:, i])\n",
        "      # compute new hidden state\n",
        "      self.h = self.relu(self.h_h(self.h))\n",
        "      # make a prediction for new character\n",
        "      outs.append(self.h_o(self.h))\n",
        "\n",
        "      \n",
        "    self.h = self.h.detach()\n",
        "    outs = torch.stack(outs, dim=1)\n",
        "    # print(outs.shape)\n",
        "\n",
        "    return outs\n",
        "  \n",
        "  \n",
        "  def reset(self):\n",
        "    self.h = 0"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBySyFk_ybR"
      },
      "source": [
        "def flat_cross_entropy(inp, targ):\n",
        "  # flatten the target from (bs, seq) -> (bs*seq)\n",
        "  # accomodate by flattening inputs (bs, seq, vocab_sz) -> (bs*seq, vocab_sz)\n",
        "  return F.cross_entropy(inp.view(bs*seq_len, -1), targ.view(-1))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZDxJYIN9655"
      },
      "source": [
        "def loss_func(inp, targ):\n",
        "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTqEtzKs12KJ",
        "outputId": "c68b2326-8878-4965-886b-de62a75e068e"
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "n9jANdP57an3",
        "outputId": "3d39daa9-a72d-4127-f3ce-aedaf39dcb47"
      },
      "source": [
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=flat_cross_entropy,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.lr_find()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(valley=0.0014454397605732083)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "I0gXSKxH9gxc",
        "outputId": "0cfdcf5c-e821-458e-f86c-2acca1c0636c"
      },
      "source": [
        "learn.fit_one_cycle(20, 0.0005)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.294538</td>\n",
              "      <td>3.288750</td>\n",
              "      <td>0.062419</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.188219</td>\n",
              "      <td>3.089181</td>\n",
              "      <td>0.144124</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.799312</td>\n",
              "      <td>2.467369</td>\n",
              "      <td>0.366455</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.171992</td>\n",
              "      <td>1.892586</td>\n",
              "      <td>0.453695</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.771753</td>\n",
              "      <td>1.852661</td>\n",
              "      <td>0.466064</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.568759</td>\n",
              "      <td>1.778843</td>\n",
              "      <td>0.473958</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.449465</td>\n",
              "      <td>1.739035</td>\n",
              "      <td>0.473145</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.373855</td>\n",
              "      <td>1.725032</td>\n",
              "      <td>0.503662</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.314535</td>\n",
              "      <td>1.790236</td>\n",
              "      <td>0.498454</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.271651</td>\n",
              "      <td>1.704142</td>\n",
              "      <td>0.524414</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.223645</td>\n",
              "      <td>1.694260</td>\n",
              "      <td>0.533610</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.184470</td>\n",
              "      <td>1.679425</td>\n",
              "      <td>0.536865</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.150489</td>\n",
              "      <td>1.690024</td>\n",
              "      <td>0.534505</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.132538</td>\n",
              "      <td>1.662835</td>\n",
              "      <td>0.547526</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.110216</td>\n",
              "      <td>1.667577</td>\n",
              "      <td>0.556885</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.093181</td>\n",
              "      <td>1.656585</td>\n",
              "      <td>0.552897</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.079023</td>\n",
              "      <td>1.670088</td>\n",
              "      <td>0.551595</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.069359</td>\n",
              "      <td>1.677417</td>\n",
              "      <td>0.549805</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.062942</td>\n",
              "      <td>1.664687</td>\n",
              "      <td>0.548014</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.058350</td>\n",
              "      <td>1.669400</td>\n",
              "      <td>0.550130</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831VNhNX_onc"
      },
      "source": [
        "### Multilayer RNN\n",
        "- Experiment with multilayer RNNs\n",
        "- Have a different hidden state in effect making the model deeper (more params to update)\n",
        "- Make the multilayer RNN from scratch\n",
        "- Make the multilayer RNN using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_knlhfh-ZAE"
      },
      "source": [
        "class LMModel2(Module):\n",
        "\n",
        "  def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "    self.n_layers = n_layers\n",
        "    self.n_hidden = n_hidden\n",
        "    self.relu = nn.ReLU()\n",
        "    # must create hidden state for each layer in the network\n",
        "    self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "\n",
        "    self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "    self.rnn_layers = []\n",
        "    # create the middle rnn layers according to n_layers\n",
        "    for i in range(n_layers):\n",
        "      self.rnn_layers.append(nn.Linear(n_hidden, n_hidden))\n",
        "    self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    outs = []\n",
        "\n",
        "    # loop through the sequence of inputs\n",
        "    for i in range(x.shape[1]):\n",
        "      # update the hidden state for the first RNN layer\n",
        "      self.h.data[0] = self.h.data[0] + self.i_h(x[:, i])\n",
        "\n",
        "      # loop through multilayers and apply them\n",
        "      for i, h_layer in enumerate(self.rnn_layers):\n",
        "        if i == 0:\n",
        "          # already dealt with input to first layer above, apply hidden layer\n",
        "          self.h.data[i] = self.relu(h_layer(self.h.data[i]))\n",
        "\n",
        "        else:\n",
        "          # pass prev activations in\n",
        "          self.h.data[i] = self.h.data[i] + self.h.data[i-1]\n",
        "          # apply new RNN layer\n",
        "          self.h.data[i] = self.relu(h_layer(self.h.data[i]))\n",
        "      \n",
        "      # at the end, go hidden to output on the last set of activations\n",
        "      outs.append(self.h_o(self.h[-1]))\n",
        "\n",
        "    # detach the gradients\n",
        "    self.h = self.h.detach()\n",
        "\n",
        "    return torch.stack(outs, dim=1)\n",
        "  \n",
        "  def reset(self):\n",
        "    # reset the hidden state on epoch or validation\n",
        "    # self.h = torch.zeros(self.n_layers, bs, self.n_hidden)\n",
        "    self.h = torch.zeros_like(self.h)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "QHaAjx2NCpwZ",
        "outputId": "de52c7b9-5e1a-47c5-c139-07e8e28afe09"
      },
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(8, 3e-3)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.316815</td>\n",
              "      <td>3.207514</td>\n",
              "      <td>0.115316</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.057730</td>\n",
              "      <td>2.902915</td>\n",
              "      <td>0.139486</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.906930</td>\n",
              "      <td>2.851313</td>\n",
              "      <td>0.139567</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.842726</td>\n",
              "      <td>2.839864</td>\n",
              "      <td>0.158447</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.816572</td>\n",
              "      <td>2.840768</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.807096</td>\n",
              "      <td>2.844675</td>\n",
              "      <td>0.133708</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.804149</td>\n",
              "      <td>2.846586</td>\n",
              "      <td>0.130859</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.803239</td>\n",
              "      <td>2.846965</td>\n",
              "      <td>0.130859</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8jq7dAdInG1"
      },
      "source": [
        "## Realizations from above\n",
        "- After writing the RNN code, I realized that it was not training\n",
        "- You cannot index into a variable in pytorch and set it partially when requires grad; a work around would be needed for this\n",
        "- If the indexing in pytorch did not require a work around, the previous model would have worked\n",
        "- Try implementing multilayer rnn with pytorch now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdzf1JElCvXI"
      },
      "source": [
        "# override the previous LMModel2 class\n",
        "class LMModel2(Module):\n",
        "  def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "    self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "    self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "    self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "    self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "\n",
        "  \n",
        "  def forward(self, x):\n",
        "    inps = self.i_h(x)\n",
        "    # this does all of the for loops and indexing to end with a final outs variable\n",
        "    outs, hid = self.rnn(inps, self.h)\n",
        "    self.h = self.h.detach()\n",
        "    return self.h_o(outs)\n",
        "  \n",
        "\n",
        "  def reset(self):\n",
        "    self.h.zero_()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "o4Y5bIWCCplK",
        "outputId": "9632a80b-f7e2-4b84-d588-68df3b9ca9c2"
      },
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.051284</td>\n",
              "      <td>2.649105</td>\n",
              "      <td>0.434570</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.175310</td>\n",
              "      <td>1.813555</td>\n",
              "      <td>0.451986</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.730105</td>\n",
              "      <td>1.923177</td>\n",
              "      <td>0.310628</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.567270</td>\n",
              "      <td>1.920882</td>\n",
              "      <td>0.332845</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.477686</td>\n",
              "      <td>1.917347</td>\n",
              "      <td>0.365804</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.401953</td>\n",
              "      <td>1.906103</td>\n",
              "      <td>0.412191</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.327616</td>\n",
              "      <td>1.951426</td>\n",
              "      <td>0.434408</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.259548</td>\n",
              "      <td>1.958533</td>\n",
              "      <td>0.455566</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.206941</td>\n",
              "      <td>1.955413</td>\n",
              "      <td>0.464681</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.166636</td>\n",
              "      <td>1.971602</td>\n",
              "      <td>0.468424</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.134248</td>\n",
              "      <td>1.941624</td>\n",
              "      <td>0.477376</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.109579</td>\n",
              "      <td>1.939061</td>\n",
              "      <td>0.484131</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.091916</td>\n",
              "      <td>1.953057</td>\n",
              "      <td>0.486003</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.080509</td>\n",
              "      <td>1.958627</td>\n",
              "      <td>0.485921</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.074618</td>\n",
              "      <td>1.960333</td>\n",
              "      <td>0.485189</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc3Y0MaoKawG",
        "outputId": "7c7a672d-3838-4e08-dd93-07592e278261"
      },
      "source": [
        "learn.model.h_o.weight"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0346,  0.3411,  0.1147,  ..., -0.0028,  0.2650, -0.1878],\n",
              "        [-0.1974,  0.2108,  0.1868,  ...,  0.2328, -0.0865, -0.2514],\n",
              "        [-0.1573, -0.1344, -0.1193,  ...,  0.1231, -0.1139, -0.2583],\n",
              "        ...,\n",
              "        [ 0.1765, -0.1864, -0.0462,  ..., -0.1489,  0.1038,  0.0881],\n",
              "        [ 0.1313, -0.0993, -0.0919,  ..., -0.1330, -0.1156,  0.0079],\n",
              "        [ 0.1888, -0.2344, -0.1772,  ..., -0.0435, -0.0884, -0.1011]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTdW1mz6KuDD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}