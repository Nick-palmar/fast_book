{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: First, make a baseline model to determine between 3's and 7's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/mnist_sample')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/storage/data/mnist_sample/train/3'),Path('/storage/data/mnist_sample/train/7')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look inside of the train folder from the path to see what is located inside\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('/storage/data/mnist_sample/train/3/55705.png'),Path('/storage/data/mnist_sample/train/3/32379.png'),Path('/storage/data/mnist_sample/train/3/36132.png'),Path('/storage/data/mnist_sample/train/3/50201.png'),Path('/storage/data/mnist_sample/train/3/39704.png'),Path('/storage/data/mnist_sample/train/3/8475.png'),Path('/storage/data/mnist_sample/train/3/5139.png'),Path('/storage/data/mnist_sample/train/3/32610.png'),Path('/storage/data/mnist_sample/train/3/7784.png'),Path('/storage/data/mnist_sample/train/3/45704.png')...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 3s and 7s\n",
    "threes = (path/'train'/'3').ls()\n",
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6265) [Path('/storage/data/mnist_sample/train/7/23645.png'),Path('/storage/data/mnist_sample/train/7/13644.png'),Path('/storage/data/mnist_sample/train/7/22228.png'),Path('/storage/data/mnist_sample/train/7/2229.png'),Path('/storage/data/mnist_sample/train/7/6064.png'),Path('/storage/data/mnist_sample/train/7/24505.png'),Path('/storage/data/mnist_sample/train/7/26356.png'),Path('/storage/data/mnist_sample/train/7/19987.png'),Path('/storage/data/mnist_sample/train/7/19592.png'),Path('/storage/data/mnist_sample/train/7/49413.png')...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sevens = (path/'train'/'7').ls()\n",
    "sevens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/UlEQVR4nGNgGK5AQ5iBgYFBycB7+s1mBgYWZCnd0uDnrxgYGDT5GRgYVqPo0l3969+/F9///fv379+/2wZMDAyMcDmZq7w3d226LsPLwJ3h8Sp6L4rGzf8Wi0NYDf++WaI6JfnVOQkIK+bWiyYpFDnelz9LIazY73+Xourzev0vHaJo0t9/4Wj+6/h3KJCBgYGBQfHVv1WcaJJX/xUxMDAwMLDc/DeFAR1wmYgzMDAwSO75d0MCQxICOK//O49LTqr33zVccoJb//1rwSHHEPHvXzsPDjmtV/8/oHsCBtTW/HuN09Def38X8uKQU7/8bxEufQwMX3eJ45bEBgD04FWZE8STZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FDD480DD550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exmaine one of the images\n",
    "example_seven = Image.open(sevens[0])\n",
    "example_seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the baseline model that makes the average 3/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the urls into a list of tensors\n",
    "threes_tensor_list = [tensor(Image.open(three_path)) for three_path in threes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sevens_tensor_list = [tensor(Image.open(seven_path)) for seven_path in sevens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# stack the tensors to create a single 3D tensor\n",
    "threes_tensor = torch.stack(threes_tensor_list)/255\n",
    "threes_tensor_2 = torch.stack(threes_tensor_list).float()/255\n",
    "\n",
    "print((threes_tensor == threes_tensor_2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single 3 and 7 tensors by stacking the list and convert the values into 0-1 range\n",
    "threes_tensor = torch.stack(threes_tensor_list)/255\n",
    "sevens_tensor = torch.stack(sevens_tensor_list)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment with shape and dimensions in pytorch\n",
    "threes_tensor.shape, threes_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to calculte the 'averaged' 3, we must take a running average through the 1st dimension (over all of the 3s)\n",
    "av_3 = threes_tensor.mean(0)\n",
    "show_image(av_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do the same for the 'averaged' 7\n",
    "av_7 = sevens_tensor.mean(0)\n",
    "show_image(av_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict between 3s and 7s, we must be able to compare between the current number and the ideal numbers\n",
    "- Attempt to implement MAE  and RMSE manually and also using the pytorch built in error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually create a mae function\n",
    "def manual_mae(num_tensor, ideal_num):\n",
    "    # note that due to broadcasting, num_tensor can be a 2D tensor or a 3D tensor (a tensor containing multiple image tensors) and pytorch will be able to cotinue with the computations\n",
    "    # take the mean over the final 2 dimensions - the image dimensions\n",
    "    return torch.mean(abs(num_tensor-ideal_num), (-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1397),\n",
       " tensor([0.1397, 0.1281, 0.1542,  ..., 0.1159, 0.1253, 0.1337]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use one a single image, then use broadcasting to use on all images\n",
    "manual_mae(threes_tensor[0], av_3), manual_mae(threes_tensor, av_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually create rmse function\n",
    "def manual_rmse(num_tensor, ideal_num):\n",
    "    return torch.sqrt(torch.mean((num_tensor - ideal_num)**2, (-2, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2532), tensor(0.2373))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_rmse(threes_tensor[0], av_3), manual_rmse(threes_tensor, av_3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_rmse = lambda num_tensor, ideal: F.mse_loss(num_tensor, ideal).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-fa4fa006808b>:1: UserWarning: Using a target size (torch.Size([28, 28])) that is different to the input size (torch.Size([6131, 28, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  pytorch_rmse = lambda num_tensor, ideal: F.mse_loss(num_tensor, ideal).sqrt()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.2532), tensor(0.2394))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_rmse(threes_tensor[0], av_3), pytorch_rmse(threes_tensor, av_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_3(input_tensor):\n",
    "    return manual_rmse(input_tensor, av_3) < manual_rmse(input_tensor, av_7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9584)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy of all 3s and all 7s\n",
    "\n",
    "acc_3 = is_3(torch.stack([tensor(Image.open(valid_3_path)) for valid_3_path in (path/'valid'/'3').ls()])/255).float().mean()\n",
    "acc_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9997)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_7 = (1 - is_3(torch.stack([tensor(Image.open(valid_7_path)) for valid_7_path in (path/'valid'/'7').ls()]))/255).float().mean()\n",
    "acc_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Use Gradient Descent using Pytorch on a few mathematical functions\n",
    "- Write step by step what each example is doing in sgd\n",
    "- Start working with a linear function\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_points = torch.arange(0, 20).float()\n",
    "x_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
